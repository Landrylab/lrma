{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1812b7a1-a204-4685-96c2-fafe5759df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pysam\n",
    "import pickle as pkl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import FancyArrow\n",
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "from scipy import stats\n",
    "from sklearn.cluster import DBSCAN\n",
    "from progressbar import ProgressBar\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from roman import toRoman\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370cc8c8-e4c8-43b6-8809-5320cb518d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='ticks', font='DejaVu Sans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a1b1cb-4809-40c8-b946-818538662a96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5340/2963890956.py:3: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  cross_parents = pd.read_csv('/mnt/HDD3/lrma/private_variants/cross_parents.txt', sep=';', header=None, index_col=0, squeeze=True)\n"
     ]
    }
   ],
   "source": [
    "#import tables of strain identities and cross parents\n",
    "nano_strains = pd.read_csv('/mnt/HDD3/lrma/script/nano_strains.csv', index_col=0)\n",
    "cross_parents = pd.read_csv('/mnt/HDD3/lrma/private_variants/cross_parents.txt', sep=';', header=None, index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b4ba56-dfb0-4204-a8ae-ac6f92a12b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_alias = {'VL3':'CC1',\n",
    "              'VL4':'CC2',\n",
    "              'VL5':'CC3',\n",
    "              'VL1':'BB1',\n",
    "              'VL2':'BB2',\n",
    "              'L1':'BC1',\n",
    "              'L2':'BC2',\n",
    "              'M1':'BA1',\n",
    "              'M2':'BA2',\n",
    "              'H1':'BSc1',\n",
    "              'H2':'BSc2'}\n",
    "cross_order = {j:i for i,j in enumerate(['CC1', 'CC2', 'CC3', 'BB1', 'BB2', 'BC1', 'BC2', 'BA1', 'BA2', 'BSc1', 'BSc2'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0361066-6b3d-4db8-a82e-37cbc103a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_subg = pd.read_csv('/mnt/HDD3/lrma/script/ns_subg.csv', index_col=0)\n",
    "ns_subg['cross'] = ns_subg['cross'].replace(cross_alias)\n",
    "ns_subg['group'] = ns_subg['subg'].replace({'MSH-604':'B',\n",
    "                                           'UWOPS-91-202':'B',\n",
    "                                           'LL2012_021':'B',\n",
    "                                           'LL2012_028':'B',\n",
    "                                           'LL2011_004':'C',\n",
    "                                           'LL2011_009':'C',\n",
    "                                           'MSH-587-1':'C',\n",
    "                                           'LL2011_012':'C',\n",
    "                                           'LL2011_001':'C',\n",
    "                                           'YPS644':'A',\n",
    "                                           'YPS744':'A',\n",
    "                                           'LL2013_040':'Sc',\n",
    "                                           'LL2013_054':'Sc'})\n",
    "ns_subg['shared_subg'] = ns_subg['subg'].replace({'MSH-604':0,\n",
    "                                           'UWOPS-91-202':0,\n",
    "                                           'LL2012_021':2,\n",
    "                                           'LL2012_028':2,\n",
    "                                           'LL2011_004':1,\n",
    "                                           'LL2011_009':1,\n",
    "                                           'MSH-587-1':2,\n",
    "                                           'LL2011_012':2,\n",
    "                                           'LL2011_001':2,\n",
    "                                           'YPS644':2,\n",
    "                                           'YPS744':2,\n",
    "                                           'LL2013_040':2,\n",
    "                                           'LL2013_054':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af35b0e-53e3-45eb-815a-d090e3f7d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "ty_colors = {'Ty1p':cm.tab10(0),\n",
    "             'TY1':cm.tab10(0),\n",
    "             'TY2':cm.tab10(1),\n",
    "             'Ty3p':cm.tab10(2),\n",
    "             'TY3':cm.tab10(2),\n",
    "             'Tsu4':cm.tab10(3),\n",
    "             'TY4':cm.tab10(4),\n",
    "             'TY5':cm.tab10(5),\n",
    "             'Ty5p':cm.tab10(5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf77d39-292c-4b36-8c79-3e5e3c132345",
   "metadata": {},
   "outputs": [],
   "source": [
    "tig_off = {}\n",
    "for r in set(ns_subg['subg']):\n",
    "    path = f'/home/mathieu/paradoxus_nanopore/MA_parents/assemblies/{r}.chromosomes.rdna.fasta'\n",
    "    tig_off[r] = pd.concat([pd.Series([seq.id, len(seq.seq)]) for seq in SeqIO.parse(path, 'fasta')], axis=1).T\n",
    "    tig_off[r].index = tig_off[r][0].values\n",
    "    tig_off[r][2] = np.concatenate([np.array([0]), np.cumsum(tig_off[r][1].values)[:-1]])\n",
    "    tig_off[r][3] = tig_off[r][1] + tig_off[r][2]\n",
    "    tig_off[r]['color'] = np.tile([0,1], 10)[:tig_off[r].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e6aae-336f-4149-9e44-8c4351ea4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gff = pd.read_csv('/mnt/HDD3/lrma/RepeatMasker/A17.MSH-604/A17.MSH-604.chroder.qry.fasta.out.gff', sep='\\t', comment='#', header=None)\n",
    "gff['fam'] = gff[8].apply(lambda x: x.split(' ')[1].strip('\"').split(':')[1])\n",
    "# subset only internal sequences\n",
    "gff = gff.loc[gff['fam'].apply(lambda x: 'LTR' not in x)]\n",
    "gff.head()\n",
    "gff[[0,3,4]].to_csv('/mnt/HDD3/lrma/RepeatMasker/A17.MSH-604/A17.MSH-604.internal.bed', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9542aa0-8fc1-470e-b44d-fa7686f51748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize liftover procedure\n",
    "bed = []\n",
    "ll_genome = {seq.id:seq for seq in SeqIO.parse('/mnt/HDD3/lrma/medaka/A88.LL2011_004/consensus.fasta', 'fasta')}\n",
    "\n",
    "for tig, seq in ll_genome.items():\n",
    "    tig_len = len(seq.seq)\n",
    "    for i in np.arange(0, tig_len-500, 500):\n",
    "        bed.append(f'{tig}\\t{i}\\t{i+500}')\n",
    "\n",
    "with open('/mnt/HDD3/lrma/minimap_aln/opt/A88.LL2011_004.tiled.bed', 'w') as handle:\n",
    "    handle.write('\\n'.join(bed))\n",
    "#(base) mathieu@mathieu-MacPro:/mnt/HDD3/lrma/minimap_aln/opt$ wc -l *.bed\n",
    "#  23254 A88.LL2011_004.tiled.bed\n",
    "#  22801 test.asm10.lift.bed\n",
    "#  22867 test.asm20.lift.bed\n",
    "#  22793 test.asm5.lift.bed\n",
    "#  91715 total\n",
    "# asm10 seems like a good choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe2c2c-558f-4bc5-8f6c-5f2d6fdaa0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "REA = []\n",
    "idx = 0\n",
    "with ProgressBar(max_value=254) as bar:\n",
    "    for s in ns_subg.loc[ns_subg['identity_filter']].index:\n",
    "\n",
    "        rea = pd.read_csv(f'/mnt/HDD3/lrma/RepeatMasker/{s}/REannotate_output/consensus.fasta.REannotation',\n",
    "                          engine='python', sep=' +', header=0)\n",
    "        rea['fl'] = rea.apply(lambda x: np.all(x[['nhits1','nhitsI','nhits2']] == 1), axis=1)\n",
    "        rea['s_subg'] = s\n",
    "        REA.append(rea)\n",
    "        idx += 1\n",
    "        bar.update(idx)\n",
    "\n",
    "REA = pd.concat(REA).reset_index(drop=True)\n",
    "REA.columns = [i.strip('\\t') for i in REA.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a136622-ed5d-4eea-bc7a-a4a5cebfb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add metadata\n",
    "REA['idx'] = REA.index\n",
    "REA['cross'] = ns_subg.loc[REA['s_subg'], 'cross'].values\n",
    "REA['subg'] = ns_subg.loc[REA['s_subg'], 'subg'].values\n",
    "\n",
    "#classify as full length, truncated, or solo\n",
    "#REA['fl'] = REA.apply(lambda x: np.all(x[['nhits1','nhitsI','nhits2']] >= 1), axis=1)\n",
    "REA['fl'] = (REA['nhits1'] >= 1) & (REA['nhits2'] >= 1) & (REA['nhitsI'] >= 1)\n",
    "#REA['I'] = REA.apply(lambda x: x['nhitsI'] == 1, axis=1)\n",
    "REA['solo'] = np.logical_xor((REA['nhits1'] >= 1), (REA['nhits2'] >= 1)) & (REA['nhitsI'] == 0)\n",
    "REA['tr'] = np.logical_xor((REA['nhits1'] >= 1), (REA['nhits2'] >= 1)) & (REA['nhitsI'] >= 1)\n",
    "REA['fl_tr'] = (REA['fl']) | (REA['tr'])\n",
    "REA['strand'] = REA['orient'].replace({'C':'-'})\n",
    "\n",
    "for o, df in REA.groupby('orient'):\n",
    "    if o == 'C':\n",
    "        REA.loc[df.index, 'start_stranded'] = df['end']\n",
    "        REA.loc[df.index, 'end_stranded'] = df['start']\n",
    "    elif o == '+':\n",
    "        REA.loc[df.index, 'start_stranded'] = df['start']\n",
    "        REA.loc[df.index, 'end_stranded'] = df['end']\n",
    "        \n",
    "REA['lift'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc307e8-b446-4961-b41d-ffb250f422d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export in bed format for liftover\n",
    "for s, df in REA.groupby('s_subg'):\n",
    "    df[['query','start_stranded','end_stranded']].astype({'start_stranded':int, 'end_stranded':int})\\\n",
    "    .to_csv(f'/mnt/HDD3/lrma/RepeatMasker/{s}/REannotate_output/{s}.bed', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eea80f-e598-4faa-8057-e4d3377f7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the position of annotations based on liftover\n",
    "\n",
    "rea_grouped = REA.groupby(['query','start_stranded','end_stranded'])\n",
    "bar_idx = 0\n",
    "with ProgressBar(max_value=254) as bar:\n",
    "    for (s,r), df in ns_subg.groupby(['s_subg','subg']):\n",
    "        path = f'/mnt/HDD3/lrma/liftover/{s}.lift.bed'\n",
    "        if os.path.isfile(path) and os.stat(path).st_size > 0:\n",
    "            bed = pd.read_csv(path, sep='\\t', header=None)\n",
    "            for i in bed.index:\n",
    "                Tig, Start, End, switch = bed.loc[i, [0,1,2,5]]\n",
    "                if switch == '-':\n",
    "                    (Start, End) = (End, Start)\n",
    "                Strand = ''\n",
    "                if Start < End:\n",
    "                    Strand = '+'\n",
    "                elif Start > End:\n",
    "                    Strand = '-'\n",
    "                tig, start, end = bed.loc[i, 3].split('_')[:3]\n",
    "                idx = rea_grouped.get_group((tig, int(start), int(end))).index\n",
    "                REA.loc[idx, 'lift'] = True\n",
    "                REA.loc[idx, 'Query'] = Tig\n",
    "\n",
    "                REA.loc[idx, 'Start'] = Start\n",
    "                REA.loc[idx, 'End'] = End\n",
    "                REA.loc[idx, 'Strand'] = Strand\n",
    "                \n",
    "            bar_idx += 1\n",
    "            bar.update(bar_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bc9da-eb2f-4b29-bd05-72d6608bdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_cluster(coords, ):\n",
    "    ((s1, e1), (s2, e2)) = coords\n",
    "    if (s2-s1 < max_dist) or (np.abs(s2-e1) < max_dist) or (e2 < e1):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d987a449-87cf-4b03-97f5-f43e34875582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define orthogroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9bff7f-6f29-4087-bc72-e384cd778c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_idx = 0\n",
    "\n",
    "max_dist = 500\n",
    "dbscan = DBSCAN(eps=max_dist, min_samples=1)\n",
    "\n",
    "for (subg, chrom, fam, strand), df in REA.groupby(['subg', 'Query', 'family', 'Strand']):\n",
    "\n",
    "    if df.shape[0] > 1:\n",
    "        POS = []\n",
    "        IDX = []\n",
    "        for i in df.index:\n",
    "            start, end = df.loc[i, ['Start', 'End']]\n",
    "            pos = np.nan\n",
    "            if strand == '+':\n",
    "                pos = np.arange(start, end, 10)\n",
    "            elif strand == '-':\n",
    "                pos = np.arange(end, start, 10)\n",
    "            POS.append(pos)\n",
    "            IDX.append(np.repeat(i, pos.shape[0]))\n",
    "\n",
    "        POS = np.concatenate(POS)\n",
    "        IDX = np.concatenate(IDX)\n",
    "        \n",
    "        clusters = dbscan.fit_predict(POS.reshape(-1,1))\n",
    "\n",
    "        clusters = pd.DataFrame(np.concatenate([POS.reshape(-1,1), IDX.reshape(-1,1), clusters.reshape(-1,1)], axis=1))\n",
    "        for c, df1 in clusters.groupby(2):\n",
    "            if c != -1:\n",
    "                cluster_name = f'og{og_idx}'\n",
    "                og_idx += 1\n",
    "                for i in set(df1[1]):\n",
    "                    REA.loc[i, 'og'] = cluster_name\n",
    "            else:\n",
    "                for i in set(df1[1]):\n",
    "                    cluster_name = f'og{og_idx}'\n",
    "                    og_idx += 1\n",
    "                    REA.loc[i, 'og'] = cluster_name\n",
    "                    \n",
    "    else:\n",
    "        cluster_name = f'og{og_idx}'\n",
    "        og_idx += 1\n",
    "        REA.loc[df.index, 'og'] = cluster_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c17a13d-1818-4e3b-b8ed-42915abd3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cross, df in REA.groupby('cross'):\n",
    "    dat = df.value_counts('og')\n",
    "    plt.plot(dat, np.linspace(0,1,dat.shape[0]), label=cross)\n",
    "    \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cddf900-fa79-4b00-bf2a-c79dfe39f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish midpoint values for orthogroups\n",
    "\n",
    "og_data = []\n",
    "\n",
    "for (subg, chrom, og), df in REA.groupby(['subg','Query','og']):\n",
    "    pos = df[['Start', 'End']].values.flatten()\n",
    "    mid = np.median(pos)\n",
    "    left_bound = np.min(pos)\n",
    "    right_bound = np.max(pos)\n",
    "    \n",
    "    if df['fl'].sum() > 0:\n",
    "        has_fl = True\n",
    "    else:\n",
    "        has_fl = False\n",
    "    \n",
    "    og_data.append([subg, chrom, og, mid, left_bound, right_bound, has_fl])\n",
    "\n",
    "og_data = pd.DataFrame(og_data, columns=['subg', 'chrom', 'og', 'mid', 'left_bound', 'right_bound','has_fl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be86e012-fbc2-4a83-b3e6-9f339aaf3de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subg</th>\n",
       "      <th>chrom</th>\n",
       "      <th>og</th>\n",
       "      <th>mid</th>\n",
       "      <th>left_bound</th>\n",
       "      <th>right_bound</th>\n",
       "      <th>has_fl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LL2011_001</td>\n",
       "      <td>chrI</td>\n",
       "      <td>og0</td>\n",
       "      <td>154352.0</td>\n",
       "      <td>154266.0</td>\n",
       "      <td>154438.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LL2011_001</td>\n",
       "      <td>chrI</td>\n",
       "      <td>og1</td>\n",
       "      <td>172319.0</td>\n",
       "      <td>171834.0</td>\n",
       "      <td>172549.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LL2011_001</td>\n",
       "      <td>chrI</td>\n",
       "      <td>og2</td>\n",
       "      <td>133265.0</td>\n",
       "      <td>133227.0</td>\n",
       "      <td>133303.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LL2011_001</td>\n",
       "      <td>chrI</td>\n",
       "      <td>og3</td>\n",
       "      <td>169125.5</td>\n",
       "      <td>168967.0</td>\n",
       "      <td>169284.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LL2011_001</td>\n",
       "      <td>chrI</td>\n",
       "      <td>og4</td>\n",
       "      <td>177168.0</td>\n",
       "      <td>174228.0</td>\n",
       "      <td>180108.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subg chrom   og       mid  left_bound  right_bound  has_fl\n",
       "0  LL2011_001  chrI  og0  154352.0    154266.0     154438.0   False\n",
       "1  LL2011_001  chrI  og1  172319.0    171834.0     172549.0   False\n",
       "2  LL2011_001  chrI  og2  133265.0    133227.0     133303.0   False\n",
       "3  LL2011_001  chrI  og3  169125.5    168967.0     169284.0   False\n",
       "4  LL2011_001  chrI  og4  177168.0    174228.0     180108.0    True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6ebba-53af-4ae6-ac6e-5c3906117914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export og_data\n",
    "#og_data.to_csv('/mnt/HDD3/lrma/results/og_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc5541-732c-4fd5-a6bf-e4fc35f1806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add og bound values to REA table\n",
    "og_data_reindex = og_data.set_index('og')\n",
    "for og, df in REA.groupby('og'):\n",
    "    mid, left_bound, right_bound, has_fl = og_data_reindex.loc[og, ['mid', 'left_bound', 'right_bound', 'has_fl']]\n",
    "    REA.loc[df.index, 'mid'] = mid\n",
    "    REA.loc[df.index, 'left_bound'] = left_bound\n",
    "    REA.loc[df.index, 'right_bound'] = right_bound\n",
    "    REA.loc[df.index, 'has_fl'] = has_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7b80b-8f18-4731-9309-e185c71a3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export REA\n",
    "#REA.to_csv('/mnt/HDD3/lrma/results/REA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff9b308-1e9b-429b-b392-f8368e7bb93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5340/1666747884.py:2: DtypeWarning: Columns (6,13,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  REA = pd.read_csv('/mnt/HDD3/lrma/results/REA.csv', index_col=0)\n"
     ]
    }
   ],
   "source": [
    "#export REA\n",
    "REA = pd.read_csv('/mnt/HDD3/lrma/results/REA.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3671d6dd-866b-45e5-a3f7-59d4234e3928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_subg.loc[ns_subg['identity_filter']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bcf8e30-ddc2-409c-bbed-c5848417022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export flanking regions for test liftover\n",
    "pad = 500\n",
    "for subg, df in og_data.groupby('subg'):\n",
    "    bed = []\n",
    "    for i in df.index:\n",
    "        chrom, lb, rb = df.loc[i, ['chrom','left_bound','right_bound']]\n",
    "        bed.append(f'{chrom}\\t{int(lb-pad)}\\t{int(lb)}')\n",
    "        bed.append(f'{chrom}\\t{int(rb)}\\t{int(rb+pad)}')\n",
    "    with open(f'/mnt/HDD3/lrma/reverse_liftover/{subg}.flank.bed', 'w') as handle:\n",
    "        handle.write('\\n'.join(bed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda8c83-cf60-4c62-a26e-f23afee39330",
   "metadata": {},
   "outputs": [],
   "source": [
    "REA.loc[REA['og']=='og4710', ['s_subg','family','query','start','end','orient','Query','Start','End','Strand']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa797069-7461-44a9-a04c-ab1f3427cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "REA.loc[REA['og']=='og4713', ['s_subg','family','query','start','end','orient','Query','Start','End','Strand']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0926a1e-6e6f-425b-a245-efe8acb92dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "REA.loc[(REA['cross']=='BSc1') & (REA['Query']=='chrI') & (REA['End']<5000) & (REA['family']=='TY5'), \n",
    "       ['s_subg','family','query','start','end','start_stranded','end_stranded','orient','Query','Start','End','Strand']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dde12c-d0d1-46a2-bf00-540b541c1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "REA.loc[(REA['cross']=='BSc1') & (REA['has_fl'])].value_counts(['Query','Strand','family','og','mid'], sort=False)#.apply(lambda x: x.iloc[0]['mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c53712-6182-45c5-a2e5-a1b3e9b749b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = REA.loc[(REA['cross']=='BSc1') & (REA['Query']=='chrI')].groupby(['family','Strand','og'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9528e72-8f73-498f-b0d8-08a0b6d9959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subg_order = {}\n",
    "for c, df in ns_subg.groupby('cross'):\n",
    "    order = df.value_counts(['subg','shared_subg']).reset_index().sort_values(by=['shared_subg','subg'])\n",
    "    subg_order[c] = dict([(j,i) for (i,j) in enumerate(order['subg'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab62e9-94d3-4404-ab4b-72549403f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "orient_off = {'+':0.15, '-':-0.15}\n",
    "strand_switch = {'+':'-', '-':'+'}\n",
    "chrom_color = {0:'0', 1:'0.4'}\n",
    "\n",
    "fig = plt.figure(figsize=[12,16])\n",
    "gs = plt.GridSpec(ncols=2, nrows=11, hspace=0.55, wspace=0.1, left=0.07, right=0.97, top=0.96, bottom=0.02)\n",
    "\n",
    "for (c, subg), df in REA.loc[REA['lift']].groupby(['cross','subg']):\n",
    "    \n",
    "    ax = fig.add_subplot(gs[cross_order[c], subg_order[c][subg]])\n",
    "    \n",
    "    S_order = dict([(j,i) for (i,j) in enumerate(sorted(set(df['s_subg'].values)))])\n",
    "    for (s, fam, strand, Strand, tr), df1 in df.groupby(['s_subg','family','strand','Strand', 'tr']):\n",
    "        if Strand == '-':\n",
    "            strand = strand_switch[strand]\n",
    "        if tr == False:\n",
    "            ax.scatter(df1[['Start','End']].mean(axis=1)*1e-6, np.repeat(S_order[s]+orient_off[strand], df1.shape[0]),\n",
    "                      color=ty_colors[fam], marker='s', s=10, alpha=0.7, lw=0, zorder=1, clip_on=False)\n",
    "        if tr == True:\n",
    "            ax.scatter(df1[['Start','End']].mean(axis=1)*1e-6, np.repeat(S_order[s]+orient_off[strand], df1.shape[0]),\n",
    "                  edgecolor=ty_colors[fam], facecolor=(1,1,1,0), marker='s', s=10, lw=1, zorder=1, clip_on=False)\n",
    "\n",
    "        ax.axhline(S_order[s], lw=0.5, color='k', zorder=0)\n",
    "        \n",
    "    ax.set_title(subg)\n",
    "    \n",
    "    ax.set_ylabel('')\n",
    "    ax.set_yticks(range(len(S_order)))\n",
    "    ax.set_ylim(0, len(S_order)-1)\n",
    "    ax.set_yticklabels([i.split('.')[0] for i in S_order], size=7)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlim(-0.05, 12.05)\n",
    "    \n",
    "    ax.scatter(range(10), range(10), s=0, zorder=0)\n",
    "    \n",
    "    for (chrom, length, start, color), df1 in tig_off[subg].groupby([0,1,2,'color']):\n",
    "        length, start = np.array([length, start])*1e-6\n",
    "\n",
    "        ar = FancyArrow(start, -1.5, length, 0, width=1, head_width=1,\n",
    "                        fc=chrom_color[color], lw=0, length_includes_head=True, clip_on=False, head_length=0)\n",
    "        ax.add_patch(ar)\n",
    "        ax.text(start+0.5*length, -1.5, chrom[3:], ha='center', va='center', size=6.5, color='w')\n",
    "        \n",
    "    if subg_order[c][subg] == 0:\n",
    "        ax.text(-0.12, 0.5, c, clip_on=False, transform=ax.transAxes, size=16, rotation=90, va='center')\n",
    "        \n",
    "    ax.spines.bottom.set_visible(False)\n",
    "    ax.spines.top.set_visible(False)\n",
    "    ax.spines.right.set_visible(False)\n",
    "        \n",
    "ax = fig.add_subplot(gs[0, :])\n",
    "ax.axis('off')\n",
    "legend_elms = [Line2D([0], [0], color='w', marker='s', ms=8, mfc=cm.tab10(i), label=l) for (i, l) in zip(range(5), ['Ty1','Ty2','Ty3','Ty4/Tsu4','Ty5'])] \\\n",
    "+ [Line2D([0], [0], color='w', marker='s', ms=8, mfc='k', lw=1, label='full-length'),\n",
    "   Line2D([0], [0], color='w', marker='s', ms=8, mec='k', mfc=(1,1,1,0), lw=1, label='truncated')]\n",
    "ax.legend(handles=legend_elms, frameon=False, ncol=7, bbox_to_anchor=(0.5, 1.2), loc=8)\n",
    "\n",
    "#sns.despine()\n",
    "plt.savefig('/mnt/HDD3/lrma/fig/TE_annot_grid.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
